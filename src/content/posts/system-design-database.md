---
title: "System Design #2: Database ì„¤ê³„ - RDBMS vs NoSQL ì„ íƒ ê°€ì´ë“œ"
description: "ëŒ€ê·œëª¨ ì‹œìŠ¤í…œì—ì„œ ì ì ˆí•œ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ì„ íƒí•˜ê³  ì„¤ê³„í•˜ëŠ” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤."
pubDate: 2026-02-06
author: "Yh Na"
tags: ["system-design", "database", "sql", "nosql", "scalability"]
draft: false
---

# System Design #2: Database ì„¤ê³„

**"SQLì„ ì“¸ê¹Œ, NoSQLì„ ì“¸ê¹Œ?"**

ê°€ì¥ ë§ì´ ë°›ëŠ” ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹µì€: **"ìƒí™©ì— ë”°ë¼ ë‹¤ë¦…ë‹ˆë‹¤."**

ì´ë²ˆ ê¸€ì—ì„œ:
- RDBMS vs NoSQL ë¹„êµ
- ì‹¤ì œ ì‚¬ìš© ì‚¬ë¡€
- Scaling ì „ëµ
- í•˜ì´ë¸Œë¦¬ë“œ ì ‘ê·¼

---

## RDBMS (SQL)

### íŠ¹ì§•

```sql
-- Schema ì •ì˜
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    name VARCHAR(100),
    email VARCHAR(255) UNIQUE,
    created_at TIMESTAMP
);

CREATE TABLE posts (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id),
    title VARCHAR(255),
    content TEXT,
    created_at TIMESTAMP
);

-- ACID ë³´ì¥
BEGIN TRANSACTION;
UPDATE accounts SET balance = balance - 100 WHERE id = 1;
UPDATE accounts SET balance = balance + 100 WHERE id = 2;
COMMIT;  -- ëª¨ë‘ ì„±ê³µ ë˜ëŠ” ëª¨ë‘ ì‹¤íŒ¨
```

**ì¥ì :**
- **ACID**: íŠ¸ëœì­ì…˜ ë³´ì¥
- **Schema**: ë°ì´í„° ë¬´ê²°ì„±
- **JOIN**: ë³µì¡í•œ ì¿¼ë¦¬
- **í‘œì¤€**: SQLì€ ì–´ë””ì„œë‚˜

**ë‹¨ì :**
- **Scaling**: ìˆ˜í‰ í™•ì¥ ì–´ë ¤ì›€
- **Schema ë³€ê²½**: ë¹„ìš© í¼
- **Performance**: ë³µì¡í•œ JOINì€ ëŠë¦¼

### ì–¸ì œ ì‚¬ìš©?

```
âœ… ê¸ˆìœµ ê±°ë˜ (ACID í•„ìˆ˜)
âœ… ì‚¬ìš©ì ê´€ë¦¬ (ê´€ê³„ ë³µì¡)
âœ… ì¬ê³  ê´€ë¦¬ (ì¼ê´€ì„± ì¤‘ìš”)
âœ… ERP, CRM

âŒ ì†Œì…œ ë¯¸ë””ì–´ í”¼ë“œ (ì½ê¸° ë§ìŒ)
âŒ ë¡œê·¸ ë°ì´í„° (ì“°ê¸° ë§ìŒ)
âŒ ì‹¤ì‹œê°„ ë¶„ì„
```

---

## NoSQL

### 1. Document Store (MongoDB, Couchbase)

```javascript
// Schema-less
{
  "_id": ObjectId("..."),
  "name": "John Doe",
  "email": "john@example.com",
  "posts": [
    {
      "title": "First Post",
      "content": "...",
      "tags": ["tech", "coding"]
    }
  ],
  "followers": [123, 456, 789]
}

// ìœ ì—°í•œ êµ¬ì¡°
{
  "_id": ObjectId("..."),
  "name": "Jane",
  "bio": "Developer",
  // posts ì—†ì–´ë„ OK!
}
```

**ì¥ì :**
- Schema ìœ ì—°
- Nested data
- Horizontal scaling

**ì‚¬ìš©ì²˜:**
- CMS (Content Management)
- User profiles
- Catalogs

### 2. Key-Value Store (Redis, DynamoDB)

```python
# Simple operations
cache.set("user:123", json.dumps(user_data))
cache.get("user:123")

# Expiration
cache.setex("session:abc", 3600, session_data)  # 1ì‹œê°„

# Atomic operations
cache.incr("page_views:homepage")
```

**ì¥ì :**
- ë§¤ìš° ë¹ ë¦„ (O(1))
- ê°„ë‹¨
- ë©”ëª¨ë¦¬ ê¸°ë°˜

**ì‚¬ìš©ì²˜:**
- Cache
- Session store
- Rate limiting
- Leaderboards

### 3. Column Store (Cassandra, HBase)

```sql
-- Wide columns
CREATE TABLE events (
    user_id bigint,
    event_time timestamp,
    event_type text,
    data map<text, text>,
    PRIMARY KEY (user_id, event_time)
) WITH CLUSTERING ORDER BY (event_time DESC);

-- Query
SELECT * FROM events 
WHERE user_id = 123 
AND event_time > '2024-01-01';
```

**ì¥ì :**
- ì“°ê¸° ìµœì í™”
- ì‹œê³„ì—´ ë°ì´í„°
- Petabyte scale

**ì‚¬ìš©ì²˜:**
- Logging
- Analytics
- IoT data
- Time series

### 4. Graph DB (Neo4j, Neptune)

```cypher
// Social network
CREATE (john:User {name: "John"})
CREATE (jane:User {name: "Jane"})
CREATE (john)-[:FOLLOWS]->(jane)

// Query: Johnì˜ ì¹œêµ¬ì˜ ì¹œêµ¬
MATCH (john:User {name: "John"})-[:FOLLOWS]->()-[:FOLLOWS]->(fof)
RETURN fof.name
```

**ì¥ì :**
- ê´€ê³„ íƒìƒ‰ ë¹ ë¦„
- ì¶”ì²œ ì‹œìŠ¤í…œ
- ì†Œì…œ ë„¤íŠ¸ì›Œí¬

**ì‚¬ìš©ì²˜:**
- LinkedIn connections
- Fraud detection
- Knowledge graphs

---

## SQL vs NoSQL ë¹„êµ

| íŠ¹ì§• | RDBMS | NoSQL |
|------|-------|-------|
| Schema | ê³ ì • | ìœ ì—° |
| Scaling | Vertical | Horizontal |
| ACID | ê°•í•¨ | ì•½í•¨ (BASE) |
| JOIN | ì§€ì› | ì œí•œì  |
| ì¼ê´€ì„± | ì¦‰ì‹œ | ìµœì¢… |
| ì‚¬ìš© | êµ¬ì¡°í™” ë°ì´í„° | ë¹„êµ¬ì¡°í™” ë°ì´í„° |

---

## CAP Theorem

**ë¶ˆê°€ëŠ¥í•œ ì‚¼ê°í˜•:**

```
   Consistency
      /\
     /  \
    /    \
   /  CA  \
  /________\
AP          CP
```

**ë™ì‹œì— 3ê°œ ëª¨ë‘ ë¶ˆê°€ëŠ¥!**

### CA (Consistency + Availability)

```
- RDBMS (ë‹¨ì¼ ë…¸ë“œ)
- íŒŒí‹°ì…˜ í—ˆìš© ì•ˆ í•¨
```

### CP (Consistency + Partition Tolerance)

```
- MongoDB (strong consistency)
- HBase
- Redis (single instance)

íŒŒí‹°ì…˜ ë°œìƒ ì‹œ: ì¼ë¶€ ë…¸ë“œ unavailable
```

### AP (Availability + Partition Tolerance)

```
- Cassandra
- DynamoDB
- Couchbase

íŒŒí‹°ì…˜ ë°œìƒ ì‹œ: ì¼ê´€ì„± ì ì‹œ í¬ê¸°
```

### ì„ íƒ

```python
# ê¸ˆìœµ: CP (ì¼ê´€ì„± > ê°€ìš©ì„±)
if transaction_system:
    return "CP"  # PostgreSQL, MongoDB

# ì†Œì…œ ë¯¸ë””ì–´: AP (ê°€ìš©ì„± > ì¼ê´€ì„±)
if social_feed:
    return "AP"  # Cassandra, DynamoDB

# ë‹¨ì¼ ë…¸ë“œ: CA
if small_scale:
    return "CA"  # MySQL, PostgreSQL
```

---

## Sharding (ë¶„í• )

### Horizontal Partitioning

**User ID ê¸°ë°˜:**

```python
def get_shard(user_id):
    num_shards = 4
    return user_id % num_shards

# user_id = 12345
# shard = 12345 % 4 = 1
# â†’ Shard 1ì— ì €ì¥
```

**Range-based:**

```python
# 0-25M: Shard 0
# 25M-50M: Shard 1
# 50M-75M: Shard 2
# 75M-100M: Shard 3

def get_shard_range(user_id):
    if user_id < 25_000_000:
        return 0
    elif user_id < 50_000_000:
        return 1
    # ...
```

**Hash-based:**

```python
import hashlib

def get_shard_hash(user_id):
    hash_value = hashlib.md5(str(user_id).encode()).hexdigest()
    return int(hash_value, 16) % num_shards

# ê· ë“± ë¶„ì‚°!
```

### Consistent Hashing

```python
class ConsistentHash:
    def __init__(self, nodes):
        self.ring = {}
        self.sorted_keys = []
        
        for node in nodes:
            for i in range(150):  # Virtual nodes
                key = self.hash(f"{node}:{i}")
                self.ring[key] = node
                self.sorted_keys.append(key)
        
        self.sorted_keys.sort()
    
    def hash(self, key):
        return int(hashlib.md5(key.encode()).hexdigest(), 16)
    
    def get_node(self, item):
        if not self.ring:
            return None
        
        key = self.hash(str(item))
        
        # Binary search
        idx = bisect.bisect_right(self.sorted_keys, key)
        if idx == len(self.sorted_keys):
            idx = 0
        
        return self.ring[self.sorted_keys[idx]]

# ì‚¬ìš©
ch = ConsistentHash(["shard1", "shard2", "shard3", "shard4"])
shard = ch.get_node(user_id)
```

**ì¥ì :**
- ë…¸ë“œ ì¶”ê°€/ì œê±° ì‹œ ìµœì†Œ ì´ë™
- ê· ë“± ë¶„ì‚°

---

## Replication

### Master-Slave

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Master  â”‚ (Write)
        â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
             â”‚ Replication
      â”Œâ”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”
      â”‚      â”‚      â”‚
  â”Œâ”€â”€â”€â–¼â”€â”€â”â”Œâ”€â”€â–¼â”€â”€â”â”Œâ”€â”€â–¼â”€â”€â”
  â”‚Slave1â”‚â”‚Slave2â”‚â”‚Slave3â”‚ (Read)
  â””â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”˜
```

**íŠ¹ì§•:**
- ëª¨ë“  write â†’ Master
- Read â†’ Slaves
- Async replication (ì•½ê°„ lag)

**êµ¬í˜„:**

```python
class Database:
    def __init__(self):
        self.master = connect("master-db")
        self.slaves = [
            connect("slave-1"),
            connect("slave-2"),
            connect("slave-3")
        ]
        self.current_slave = 0
    
    def write(self, query):
        return self.master.execute(query)
    
    def read(self, query, consistent=False):
        if consistent:
            # Strong consistency: Read from master
            return self.master.execute(query)
        
        # Eventually consistent: Read from slave
        slave = self.slaves[self.current_slave]
        self.current_slave = (self.current_slave + 1) % len(self.slaves)
        return slave.execute(query)
```

### Multi-Master

```
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚ Master1 â”‚â—„â”€â”€â”€â–ºâ”‚ Master2 â”‚
  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
       â”‚               â”‚
     Slaves          Slaves
```

**íŠ¹ì§•:**
- ì–‘ìª½ write ê°€ëŠ¥
- ì¶©ëŒ í•´ê²° í•„ìš”
- ì§€ì—­ë³„ ë°°ì¹˜ (Geo-distributed)

**ì¶©ëŒ í•´ê²°:**

```python
# Last Write Wins (LWW)
def resolve_conflict(version_a, version_b):
    return version_a if version_a.timestamp > version_b.timestamp else version_b

# Vector Clocks
def merge_versions(version_a, version_b):
    if dominates(version_a.vector, version_b.vector):
        return version_a
    elif dominates(version_b.vector, version_a.vector):
        return version_b
    else:
        # Conflict: ì‚¬ìš©ì ê°œì… í•„ìš”
        return ask_user_to_resolve(version_a, version_b)
```

---

## Indexing

### B-Tree Index (ê¸°ë³¸)

```sql
-- Create index
CREATE INDEX idx_user_email ON users(email);

-- Query (fast!)
SELECT * FROM users WHERE email = 'john@example.com';
-- Index seek: O(log n)

-- Without index
-- Full table scan: O(n)
```

### Composite Index

```sql
-- Create
CREATE INDEX idx_user_created ON users(status, created_at);

-- Good
SELECT * FROM users WHERE status = 'active' AND created_at > '2024-01-01';

-- Bad (index not used)
SELECT * FROM users WHERE created_at > '2024-01-01';
-- statusëŠ” ì•ì— ì™€ì•¼ index ì‚¬ìš©!
```

### Covering Index

```sql
-- Index includes all columns
CREATE INDEX idx_user_cover ON users(email, name, created_at);

-- Query
SELECT email, name, created_at FROM users WHERE email = 'john@example.com';
-- Indexë§Œìœ¼ë¡œ í•´ê²°! (No table access)
```

### Full-Text Search

```sql
-- PostgreSQL
CREATE INDEX idx_posts_search ON posts USING GIN(to_tsvector('english', title || ' ' || content));

-- Query
SELECT * FROM posts 
WHERE to_tsvector('english', title || ' ' || content) @@ to_tsquery('postgres & database');
```

**Elasticsearch (ì „ë¬¸ ê²€ìƒ‰):**

```python
from elasticsearch import Elasticsearch

es = Elasticsearch()

# Index
es.index(
    index="posts",
    id=post_id,
    body={
        "title": "PostgreSQL Tutorial",
        "content": "Learn about PostgreSQL...",
        "tags": ["database", "sql"]
    }
)

# Search
results = es.search(
    index="posts",
    body={
        "query": {
            "multi_match": {
                "query": "postgres database",
                "fields": ["title^2", "content", "tags"]  # title 2ë°° ê°€ì¤‘ì¹˜
            }
        }
    }
)
```

---

## ì‹¤ì „ ì‚¬ë¡€: Instagram

### ìš”êµ¬ì‚¬í•­

```
- 1B+ photos
- 100M+ users
- 500M+ requests/day
- Sub-second response
```

### ì„¤ê³„

**1. PostgreSQL (Metadata)**

```sql
-- Users
CREATE TABLE users (
    id BIGINT PRIMARY KEY,
    username VARCHAR(50) UNIQUE,
    created_at TIMESTAMP
);

-- Photos
CREATE TABLE photos (
    id BIGINT PRIMARY KEY,
    user_id BIGINT REFERENCES users(id),
    url VARCHAR(255),
    created_at TIMESTAMP,
    INDEX idx_user_photos (user_id, created_at)
);

-- Sharded by user_id
-- 100 shards
```

**2. Cassandra (Feed)**

```sql
-- User timeline (home feed)
CREATE TABLE user_feed (
    user_id BIGINT,
    photo_id BIGINT,
    posted_at TIMESTAMP,
    PRIMARY KEY (user_id, posted_at)
) WITH CLUSTERING ORDER BY (posted_at DESC);

-- Fast read: SELECT * FROM user_feed WHERE user_id = ? LIMIT 20;
```

**3. Redis (Cache)**

```python
# Hot users' feeds
cache.set(f"feed:{user_id}", json.dumps(feed), ttl=300)

# Like counts
cache.incr(f"likes:{photo_id}")

# Session
cache.setex(f"session:{token}", 3600, user_id)
```

**4. S3 (Photos)**

```python
# Upload
s3.upload_file(
    photo_data,
    bucket="instagram-photos",
    key=f"{user_id}/{photo_id}.jpg"
)

# CDN
photo_url = f"https://cdn.instagram.com/{user_id}/{photo_id}.jpg"
```

### ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚    CDN    â”‚ (Photos)
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
     â”‚
â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Load Balancer â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  API       â”‚  API     â”‚  API    â”‚
â”‚ Server 1   â”‚ Server 2 â”‚ Server 3â”‚
â””â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
    â”‚                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”            â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
â”‚  Redis   â”‚            â”‚Cassandra â”‚
â”‚ (Cache)  â”‚            â”‚ (Feed)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                        â”‚
â”Œâ”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
â”‚   PostgreSQL         â”‚    S3    â”‚
â”‚   (Metadata)         â”‚ (Photos) â”‚
â”‚   100 shards         â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ìš”ì•½

**ì„ íƒ ê°€ì´ë“œ:**

```python
def choose_database(requirements):
    if requirements.acid and requirements.relations:
        return "PostgreSQL/MySQL"
    
    if requirements.flexible_schema:
        return "MongoDB"
    
    if requirements.high_writes and requirements.time_series:
        return "Cassandra"
    
    if requirements.graph_traversal:
        return "Neo4j"
    
    if requirements.cache:
        return "Redis"
    
    # í•˜ì´ë¸Œë¦¬ë“œ!
    return "Multiple databases"
```

**í•µì‹¬ ì›ì¹™:**

1. **Polyglot Persistence**: ì—¬ëŸ¬ DB ì¡°í•©
2. **Right tool for the job**: ì ì¬ì ì†Œ
3. **Start simple**: ì²˜ìŒì—” ë‹¨ìˆœí•˜ê²Œ
4. **Scale when needed**: í•„ìš”í•  ë•Œ í™•ì¥

**ë‹¤ìŒ ê¸€:**
- **Caching Strategies**: Redis ì‹¬í™”
- **Message Queue**: Kafka, RabbitMQ
- **Microservices**: ì„œë¹„ìŠ¤ ë¶„ë¦¬

ê¸°ëŒ€í•´ì£¼ì„¸ìš”! ğŸš€

---

*ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ [GitHub](https://github.com/yhna941)ì—ì„œ í™˜ì˜í•©ë‹ˆë‹¤!*
