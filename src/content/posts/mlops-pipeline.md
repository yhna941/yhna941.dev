---
title: "MLOps #1: ML íŒŒì´í”„ë¼ì¸ - Trainingë¶€í„° Productionê¹Œì§€"
description: "ì‹¤ì „ ML ì‹œìŠ¤í…œì˜ ì „ì²´ íŒŒì´í”„ë¼ì¸ êµ¬ì¶•ê³¼ ìë™í™” ë°©ë²•ì„ ì•Œì•„ë´…ë‹ˆë‹¤."
pubDate: 2026-02-06
author: "Yh Na"
tags: ["mlops", "pipeline", "production-ml", "automation", "ml-system"]
draft: false
---

# MLOps #1: ML íŒŒì´í”„ë¼ì¸

**"ëª¨ë¸ í•™ìŠµì´ ëì´ ì•„ë‹ˆë‹¤"**

ì—°êµ¬ì™€ í”„ë¡œë•ì…˜ì˜ ì°¨ì´:
```
Research:
Jupyter Notebook â†’ ëª¨ë¸ í•™ìŠµ â†’ acc 95% â†’ ë…¼ë¬¸ ì œì¶œ âœ…

Production:
ë°ì´í„° ìˆ˜ì§‘ â†’ ì „ì²˜ë¦¬ â†’ í•™ìŠµ â†’ í‰ê°€ â†’ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§ 
â†’ ì¬í•™ìŠµ â†’ ë‹¤ì‹œ ë°°í¬ â†’ ëª¨ë‹ˆí„°ë§ â†’ ... (ë¬´í•œ ë°˜ë³µ)
```

---

## ML ì‹œìŠ¤í…œì˜ í˜„ì‹¤

### ì½”ë“œì˜ 5%ë§Œ ML

**ì‹¤ì œ ML ì‹œìŠ¤í…œ:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚     Configuration (ì„¤ì • ê´€ë¦¬)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Collection (ë°ì´í„° ìˆ˜ì§‘)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data Verification (ê²€ì¦)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Feature Engineering (íŠ¹ì„± ì¶”ì¶œ)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—                  â”‚
â”‚  â•‘   ML Code    â•‘  â† 5%ë§Œ!         â”‚
â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Model Analysis (ë¶„ì„)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Serving Infrastructure (ë°°í¬)     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Monitoring (ëª¨ë‹ˆí„°ë§)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Resource Management (ë¦¬ì†ŒìŠ¤)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Googleì˜ í†µê³„ (Hidden Technical Debt in ML Systems):**
- ML ì½”ë“œ: 5%
- ì¸í”„ë¼/íŒŒì´í”„ë¼ì¸: 95%

---

## ML íŒŒì´í”„ë¼ì¸ ê°œìš”

### ì „ì²´ íë¦„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Source  â”‚ (S3, DB, API)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Data Pipelineâ”‚ (ìˆ˜ì§‘, ì •ì œ)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training   â”‚ (ëª¨ë¸ í•™ìŠµ)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Validation  â”‚ (í‰ê°€, ê²€ì¦)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Registry    â”‚ (ëª¨ë¸ ì €ì¥)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Deployment  â”‚ (ë°°í¬)
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Monitoring  â”‚ (ì„±ëŠ¥ ì¶”ì )
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” (ì¬í•™ìŠµ íŠ¸ë¦¬ê±°)
                  â”‚
            â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚ Retrain?   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 1. Data Pipeline

### ë°ì´í„° ìˆ˜ì§‘

```python
import pandas as pd
from datetime import datetime, timedelta
from sqlalchemy import create_engine
import boto3

class DataCollector:
    def __init__(self, db_url, s3_bucket):
        self.engine = create_engine(db_url)
        self.s3 = boto3.client('s3')
        self.bucket = s3_bucket
    
    def collect_daily_data(self, date):
        """ì¼ì¼ ë°ì´í„° ìˆ˜ì§‘"""
        # 1. DBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        query = f"""
        SELECT user_id, action, timestamp, features
        FROM user_events
        WHERE date = '{date}'
        """
        
        df = pd.read_sql(query, self.engine)
        
        # 2. S3ì— ì €ì¥ (Parquet í¬ë§·)
        s3_key = f"raw_data/{date}/events.parquet"
        
        df.to_parquet(
            f"s3://{self.bucket}/{s3_key}",
            compression='snappy',
            index=False
        )
        
        print(f"Collected {len(df)} records for {date}")
        return s3_key
    
    def collect_streaming_data(self, kafka_topic):
        """ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ (Kafka)"""
        from kafka import KafkaConsumer
        import json
        
        consumer = KafkaConsumer(
            kafka_topic,
            bootstrap_servers=['localhost:9092'],
            value_deserializer=lambda m: json.loads(m.decode('utf-8'))
        )
        
        batch = []
        batch_size = 1000
        
        for message in consumer:
            batch.append(message.value)
            
            if len(batch) >= batch_size:
                # ë°°ì¹˜ ì²˜ë¦¬
                df = pd.DataFrame(batch)
                self.save_batch(df)
                batch = []
```

### ë°ì´í„° ê²€ì¦

```python
import great_expectations as ge
from typing import Dict, List

class DataValidator:
    def __init__(self, expectations_suite):
        self.suite = expectations_suite
    
    def validate(self, df: pd.DataFrame) -> Dict:
        """ë°ì´í„° í’ˆì§ˆ ê²€ì¦"""
        # Great Expectationsë¡œ ê²€ì¦
        gdf = ge.from_pandas(df)
        
        results = gdf.validate(
            expectation_suite=self.suite,
            only_return_failures=False
        )
        
        return {
            'success': results['success'],
            'failed_expectations': [
                exp for exp in results['results']
                if not exp['success']
            ],
            'statistics': results['statistics']
        }
    
    def create_expectations(self):
        """ë°ì´í„° ê²€ì¦ ë£° ì •ì˜"""
        expectations = [
            # 1. ì»¬ëŸ¼ ì¡´ì¬
            {
                'expectation_type': 'expect_table_columns_to_match_ordered_list',
                'kwargs': {
                    'column_list': ['user_id', 'action', 'timestamp', 'features']
                }
            },
            # 2. Null ì²´í¬
            {
                'expectation_type': 'expect_column_values_to_not_be_null',
                'kwargs': {'column': 'user_id'}
            },
            # 3. ê°’ ë²”ìœ„
            {
                'expectation_type': 'expect_column_values_to_be_between',
                'kwargs': {
                    'column': 'age',
                    'min_value': 0,
                    'max_value': 150
                }
            },
            # 4. ì¹´í…Œê³ ë¦¬
            {
                'expectation_type': 'expect_column_values_to_be_in_set',
                'kwargs': {
                    'column': 'action',
                    'value_set': ['click', 'view', 'purchase']
                }
            }
        ]
        
        return expectations

# ì‚¬ìš©
validator = DataValidator(expectations_suite)
df = pd.read_parquet('s3://bucket/raw_data/2024-01-01/events.parquet')

validation_result = validator.validate(df)

if not validation_result['success']:
    print("Validation failed!")
    for failure in validation_result['failed_expectations']:
        print(f"- {failure['expectation_config']['expectation_type']}")
    # ì•ŒëŒ ë°œì†¡
    send_alert("Data validation failed", validation_result)
```

### Feature Engineering Pipeline

```python
from sklearn.base import BaseEstimator, TransformerMixin
from sklearn.pipeline import Pipeline
import numpy as np

class FeatureEngineer:
    def __init__(self):
        self.pipeline = self.build_pipeline()
    
    def build_pipeline(self) -> Pipeline:
        """Feature ë³€í™˜ íŒŒì´í”„ë¼ì¸"""
        return Pipeline([
            ('imputer', ImputeMissing()),
            ('encoder', EncodeCategories()),
            ('scaler', ScaleFeatures()),
            ('engineer', CreateFeatures())
        ])
    
    def fit_transform(self, df: pd.DataFrame) -> np.ndarray:
        """í•™ìŠµ + ë³€í™˜"""
        return self.pipeline.fit_transform(df)
    
    def transform(self, df: pd.DataFrame) -> np.ndarray:
        """ë³€í™˜ë§Œ (ì¶”ë¡  ì‹œ)"""
        return self.pipeline.transform(df)
    
    def save(self, path: str):
        """íŒŒì´í”„ë¼ì¸ ì €ì¥"""
        import joblib
        joblib.dump(self.pipeline, path)

class ImputeMissing(BaseEstimator, TransformerMixin):
    """ê²°ì¸¡ì¹˜ ì²˜ë¦¬"""
    def fit(self, X, y=None):
        self.fill_values_ = {}
        for col in X.columns:
            if X[col].dtype in [np.float64, np.int64]:
                self.fill_values_[col] = X[col].median()
            else:
                self.fill_values_[col] = X[col].mode()[0]
        return self
    
    def transform(self, X):
        X = X.copy()
        for col, value in self.fill_values_.items():
            X[col].fillna(value, inplace=True)
        return X

class CreateFeatures(BaseEstimator, TransformerMixin):
    """íŒŒìƒ ë³€ìˆ˜ ìƒì„±"""
    def fit(self, X, y=None):
        return self
    
    def transform(self, X):
        X = X.copy()
        
        # ì‹œê°„ ê¸°ë°˜ íŠ¹ì„±
        X['hour'] = pd.to_datetime(X['timestamp']).dt.hour
        X['day_of_week'] = pd.to_datetime(X['timestamp']).dt.dayofweek
        X['is_weekend'] = X['day_of_week'].isin([5, 6]).astype(int)
        
        # ì‚¬ìš©ì í–‰ë™ íŠ¹ì„±
        X['action_count'] = X.groupby('user_id')['action'].transform('count')
        X['avg_session_length'] = X.groupby('user_id')['session_length'].transform('mean')
        
        return X
```

---

## 2. Training Pipeline

### í•™ìŠµ ìë™í™”

```python
from typing import Dict, Any
import mlflow
import torch
import torch.nn as nn
from torch.utils.data import DataLoader

class TrainingPipeline:
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.model = None
        self.best_metric = float('inf')
    
    def run(self, train_data, val_data):
        """ì „ì²´ í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰"""
        # 1. MLflow ì‹¤í—˜ ì‹œì‘
        mlflow.set_experiment(self.config['experiment_name'])
        
        with mlflow.start_run():
            # 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
            mlflow.log_params(self.config)
            
            # 3. ëª¨ë¸ ì´ˆê¸°í™”
            self.model = self.build_model()
            
            # 4. í•™ìŠµ
            history = self.train(train_data, val_data)
            
            # 5. í‰ê°€
            metrics = self.evaluate(val_data)
            mlflow.log_metrics(metrics)
            
            # 6. ëª¨ë¸ ì €ì¥ (bestë§Œ)
            if metrics['val_loss'] < self.best_metric:
                self.save_model(self.model)
                mlflow.pytorch.log_model(self.model, "model")
                self.best_metric = metrics['val_loss']
            
            # 7. ì•„í‹°íŒ©íŠ¸ ì €ì¥
            mlflow.log_artifact("training_history.json")
            mlflow.log_artifact("confusion_matrix.png")
            
            return metrics
    
    def build_model(self) -> nn.Module:
        """ëª¨ë¸ ìƒì„±"""
        model = YourModel(
            input_dim=self.config['input_dim'],
            hidden_dim=self.config['hidden_dim'],
            output_dim=self.config['output_dim']
        )
        return model
    
    def train(self, train_data, val_data) -> Dict:
        """í•™ìŠµ ë£¨í”„"""
        optimizer = torch.optim.Adam(
            self.model.parameters(),
            lr=self.config['learning_rate']
        )
        criterion = nn.CrossEntropyLoss()
        
        history = {'train_loss': [], 'val_loss': []}
        
        for epoch in range(self.config['epochs']):
            # Training
            self.model.train()
            train_loss = 0
            
            for batch in train_data:
                optimizer.zero_grad()
                
                outputs = self.model(batch['features'])
                loss = criterion(outputs, batch['labels'])
                
                loss.backward()
                optimizer.step()
                
                train_loss += loss.item()
            
            # Validation
            val_loss = self.validate(val_data, criterion)
            
            history['train_loss'].append(train_loss / len(train_data))
            history['val_loss'].append(val_loss)
            
            # MLflow ë¡œê¹…
            mlflow.log_metrics({
                'train_loss': train_loss / len(train_data),
                'val_loss': val_loss
            }, step=epoch)
            
            print(f"Epoch {epoch+1}: train_loss={train_loss:.4f}, val_loss={val_loss:.4f}")
        
        return history
    
    def validate(self, val_data, criterion) -> float:
        """ê²€ì¦"""
        self.model.eval()
        val_loss = 0
        
        with torch.no_grad():
            for batch in val_data:
                outputs = self.model(batch['features'])
                loss = criterion(outputs, batch['labels'])
                val_loss += loss.item()
        
        return val_loss / len(val_data)
    
    def evaluate(self, test_data) -> Dict:
        """ìµœì¢… í‰ê°€"""
        self.model.eval()
        
        all_preds = []
        all_labels = []
        
        with torch.no_grad():
            for batch in test_data:
                outputs = self.model(batch['features'])
                preds = torch.argmax(outputs, dim=1)
                
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(batch['labels'].cpu().numpy())
        
        # Metrics
        from sklearn.metrics import accuracy_score, f1_score, confusion_matrix
        
        metrics = {
            'accuracy': accuracy_score(all_labels, all_preds),
            'f1': f1_score(all_labels, all_preds, average='weighted'),
        }
        
        # Confusion matrix
        cm = confusion_matrix(all_labels, all_preds)
        self.plot_confusion_matrix(cm)
        
        return metrics
    
    def save_model(self, model):
        """ëª¨ë¸ ì €ì¥"""
        torch.save({
            'model_state_dict': model.state_dict(),
            'config': self.config,
        }, 'model.pt')

# ì‚¬ìš©
config = {
    'experiment_name': 'user_behavior_prediction',
    'input_dim': 128,
    'hidden_dim': 256,
    'output_dim': 3,
    'learning_rate': 0.001,
    'epochs': 50,
    'batch_size': 32
}

pipeline = TrainingPipeline(config)
metrics = pipeline.run(train_loader, val_loader)
```

---

## 3. Model Registry

### ëª¨ë¸ ë²„ì €ë‹

```python
import mlflow
from mlflow.tracking import MlflowClient

class ModelRegistry:
    def __init__(self, tracking_uri):
        mlflow.set_tracking_uri(tracking_uri)
        self.client = MlflowClient()
    
    def register_model(
        self,
        model_name: str,
        run_id: str,
        description: str = None
    ):
        """ëª¨ë¸ ë“±ë¡"""
        # ëª¨ë¸ ë“±ë¡
        model_uri = f"runs:/{run_id}/model"
        
        mv = mlflow.register_model(
            model_uri,
            model_name
        )
        
        # ì„¤ëª… ì¶”ê°€
        if description:
            self.client.update_model_version(
                name=model_name,
                version=mv.version,
                description=description
            )
        
        print(f"Registered {model_name} version {mv.version}")
        return mv
    
    def promote_to_production(self, model_name: str, version: int):
        """í”„ë¡œë•ì…˜ìœ¼ë¡œ ìŠ¹ê²©"""
        # ê¸°ì¡´ production ëª¨ë¸ â†’ archived
        for mv in self.client.search_model_versions(f"name='{model_name}'"):
            if mv.current_stage == "Production":
                self.client.transition_model_version_stage(
                    name=model_name,
                    version=mv.version,
                    stage="Archived"
                )
        
        # ìƒˆ ë²„ì „ â†’ production
        self.client.transition_model_version_stage(
            name=model_name,
            version=version,
            stage="Production"
        )
        
        print(f"Promoted {model_name} v{version} to Production")
    
    def get_production_model(self, model_name: str):
        """í”„ë¡œë•ì…˜ ëª¨ë¸ ê°€ì ¸ì˜¤ê¸°"""
        model_uri = f"models:/{model_name}/Production"
        model = mlflow.pytorch.load_model(model_uri)
        return model
    
    def compare_models(self, model_name: str, versions: List[int]):
        """ëª¨ë¸ ë²„ì „ ë¹„êµ"""
        results = []
        
        for version in versions:
            # ëª¨ë¸ ë©”íŠ¸ë¦­ ê°€ì ¸ì˜¤ê¸°
            mv = self.client.get_model_version(model_name, version)
            run = self.client.get_run(mv.run_id)
            
            results.append({
                'version': version,
                'stage': mv.current_stage,
                'metrics': run.data.metrics,
                'created': mv.creation_timestamp
            })
        
        return pd.DataFrame(results)

# ì‚¬ìš©
registry = ModelRegistry(tracking_uri="http://localhost:5000")

# ëª¨ë¸ ë“±ë¡
mv = registry.register_model(
    model_name="user_behavior_model",
    run_id="abc123",
    description="Transformer-based model with 95% accuracy"
)

# í”„ë¡œë•ì…˜ ìŠ¹ê²©
registry.promote_to_production("user_behavior_model", version=5)

# ëª¨ë¸ ë¹„êµ
comparison = registry.compare_models("user_behavior_model", versions=[3, 4, 5])
print(comparison)
```

---

## 4. Deployment Pipeline

### CI/CD for ML

```yaml
# .github/workflows/ml-pipeline.yml
name: ML Pipeline

on:
  push:
    branches: [main]
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ 2am ì¬í•™ìŠµ

jobs:
  data-validation:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Validate Data
        run: |
          python scripts/validate_data.py
          
      - name: Upload validation report
        uses: actions/upload-artifact@v2
        with:
          name: validation-report
          path: validation_report.html

  training:
    needs: data-validation
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      
      - name: Train Model
        env:
          MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_URI }}
        run: |
          python scripts/train.py --config configs/production.yaml
      
      - name: Evaluate Model
        run: |
          python scripts/evaluate.py
      
      - name: Check metrics threshold
        run: |
          python scripts/check_threshold.py --min-accuracy 0.90

  deployment:
    needs: training
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to staging
        run: |
          kubectl apply -f k8s/staging/
      
      - name: Run integration tests
        run: |
          python scripts/integration_test.py --env staging
      
      - name: Deploy to production
        if: success()
        run: |
          kubectl apply -f k8s/production/
```

### Kubernetes ë°°í¬

```yaml
# k8s/production/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-model-server
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-model
  template:
    metadata:
      labels:
        app: ml-model
        version: v5
    spec:
      containers:
      - name: model-server
        image: your-registry/ml-model:v5
        ports:
        - containerPort: 8000
        env:
        - name: MODEL_NAME
          value: "user_behavior_model"
        - name: MODEL_VERSION
          value: "5"
        - name: MLFLOW_TRACKING_URI
          valueFrom:
            secretKeyRef:
              name: mlflow-secret
              key: tracking-uri
        resources:
          requests:
            memory: "2Gi"
            cpu: "1"
          limits:
            memory: "4Gi"
            cpu: "2"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 8000
          initialDelaySeconds: 5
          periodSeconds: 5
---
apiVersion: v1
kind: Service
metadata:
  name: ml-model-service
spec:
  selector:
    app: ml-model
  ports:
  - port: 80
    targetPort: 8000
  type: LoadBalancer
```

---

## 5. ì „ì²´ íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### Airflow DAG

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from airflow.operators.bash import BashOperator
from datetime import datetime, timedelta

default_args = {
    'owner': 'ml-team',
    'depends_on_past': False,
    'start_date': datetime(2024, 1, 1),
    'email': ['ml-team@company.com'],
    'email_on_failure': True,
    'retries': 2,
    'retry_delay': timedelta(minutes=5)
}

dag = DAG(
    'ml_training_pipeline',
    default_args=default_args,
    description='Daily ML model training pipeline',
    schedule_interval='0 2 * * *',  # ë§¤ì¼ 2am
    catchup=False
)

# Task 1: ë°ì´í„° ìˆ˜ì§‘
collect_data = PythonOperator(
    task_id='collect_data',
    python_callable=collect_daily_data,
    op_kwargs={'date': '{{ ds }}'},
    dag=dag
)

# Task 2: ë°ì´í„° ê²€ì¦
validate_data = PythonOperator(
    task_id='validate_data',
    python_callable=validate_data_quality,
    dag=dag
)

# Task 3: Feature Engineering
create_features = PythonOperator(
    task_id='create_features',
    python_callable=create_feature_pipeline,
    dag=dag
)

# Task 4: ëª¨ë¸ í•™ìŠµ
train_model = BashOperator(
    task_id='train_model',
    bash_command='python scripts/train.py --date {{ ds }}',
    dag=dag
)

# Task 5: ëª¨ë¸ í‰ê°€
evaluate_model = PythonOperator(
    task_id='evaluate_model',
    python_callable=evaluate_and_register,
    dag=dag
)

# Task 6: ë°°í¬ (ì¡°ê±´ë¶€)
deploy_model = PythonOperator(
    task_id='deploy_model',
    python_callable=deploy_if_better,
    dag=dag
)

# ì˜ì¡´ì„± ì„¤ì •
collect_data >> validate_data >> create_features >> train_model >> evaluate_model >> deploy_model
```

---

## ìš”ì•½

**ML íŒŒì´í”„ë¼ì¸ í•µì‹¬:**

1. **Data Pipeline**: ìˆ˜ì§‘ â†’ ê²€ì¦ â†’ íŠ¹ì„± ì¶”ì¶œ
2. **Training Pipeline**: í•™ìŠµ â†’ í‰ê°€ â†’ ë¡œê¹…
3. **Model Registry**: ë²„ì €ë‹ â†’ ë¹„êµ â†’ ìŠ¹ê²©
4. **Deployment**: CI/CD â†’ K8s â†’ ëª¨ë‹ˆí„°ë§
5. **Orchestration**: Airflowë¡œ ìë™í™”

**í•µì‹¬ ë„êµ¬:**
- MLflow: ì‹¤í—˜ ì¶”ì , ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
- Great Expectations: ë°ì´í„° ê²€ì¦
- Airflow: íŒŒì´í”„ë¼ì¸ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
- Kubernetes: ë°°í¬ ë° ìŠ¤ì¼€ì¼ë§

**Best Practices:**
- ëª¨ë“  ê²ƒì„ ì½”ë“œë¡œ (Infrastructure as Code)
- ë²„ì „ ê´€ë¦¬ (ë°ì´í„°, ëª¨ë¸, ì½”ë“œ)
- ìë™í™” (CI/CD)
- ëª¨ë‹ˆí„°ë§ í•„ìˆ˜

**ë‹¤ìŒ ê¸€:**
- **MLOps #2**: ì‹¤í—˜ ê´€ë¦¬ (MLflow, W&B ì‹¬í™”)
- **MLOps #3**: ëª¨ë‹ˆí„°ë§ & ì•ŒëŒ
- **Serving #1**: ì¶”ë¡  ìµœì í™”

ê¸°ëŒ€í•´ì£¼ì„¸ìš”! ğŸš€

---

*ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ [GitHub](https://github.com/yhna941)ì—ì„œ í™˜ì˜í•©ë‹ˆë‹¤!*
