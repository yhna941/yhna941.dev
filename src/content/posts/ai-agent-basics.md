---
title: "AI Agent #1: Agentì˜ ê¸°ì´ˆ - ReActì™€ Tool Use"
description: "LLMì´ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ê³  ì¶”ë¡ í•˜ëŠ” AI Agentì˜ ê¸°ë³¸ ì›ë¦¬ì™€ êµ¬í˜„ì„ ì•Œì•„ë´…ë‹ˆë‹¤."
pubDate: 2026-02-06
author: "Yh Na"
tags: ["ai-agent", "llm", "react", "tool-use", "reasoning"]
draft: false
---

# AI Agent #1: Agentì˜ ê¸°ì´ˆ

**"LLM + Tools = Agent"**

ChatGPTëŠ” ëŒ€í™”ë§Œ í•©ë‹ˆë‹¤. í•˜ì§€ë§Œ AgentëŠ”:
- ì›¹ ê²€ìƒ‰
- ì½”ë“œ ì‹¤í–‰
- íŒŒì¼ ì½ê¸°/ì“°ê¸°
- API í˜¸ì¶œ

**ì§„ì§œ ìœ ìš©í•œ AI!**

---

## Agentë€?

### ì •ì˜

> **í™˜ê²½ì„ ì¸ì‹í•˜ê³ , ëª©í‘œ ë‹¬ì„±ì„ ìœ„í•´ í–‰ë™í•˜ëŠ” ì‹œìŠ¤í…œ**

```
User: "ì˜¤ëŠ˜ ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"

ì¼ë°˜ LLM:
"ì£„ì†¡í•©ë‹ˆë‹¤. ì‹¤ì‹œê°„ ì •ë³´ëŠ” ëª¨ë¦…ë‹ˆë‹¤."

Agent:
1. "ë‚ ì”¨ API ì‚¬ìš©í•´ì•¼ê² ë‹¤" (Reasoning)
2. weather_api.get("Seoul") (Action)
3. "ì„œìš¸ì€ í˜„ì¬ 15ë„, ë§‘ìŒì…ë‹ˆë‹¤" (Response)
```

### êµ¬ì„± ìš”ì†Œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Loop        â”‚
â”‚                     â”‚
â”‚  1. Observe         â”‚ â† Environment
â”‚  2. Think           â”‚
â”‚  3. Act             â”‚ â†’ Environment
â”‚  4. Repeat          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ReAct (Reasoning + Acting)

**ë…¼ë¬¸: ReAct (2022)**

### í•µì‹¬ ì•„ì´ë””ì–´

**ê¸°ì¡´ ë°©ë²•ë“¤:**

```
Chain-of-Thought (CoT):
- ì¶”ë¡ ë§Œ (Thought â†’ Thought â†’ Answer)
- í–‰ë™ ì—†ìŒ

Act-only:
- í–‰ë™ë§Œ (Action â†’ Action â†’ Answer)
- ì¶”ë¡  ì—†ìŒ
```

**ReAct:**

> "ì¶”ë¡ ê³¼ í–‰ë™ì„ ë²ˆê°ˆì•„ê°€ë©°!"

```
Thought â†’ Action â†’ Observation â†’
Thought â†’ Action â†’ Observation â†’
...
â†’ Answer
```

### ì˜ˆì‹œ

**ì§ˆë¬¸:** "í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ì˜ ë‚˜ì´ëŠ”?"

```
Thought 1: ë¨¼ì € í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ì´ ëˆ„êµ°ì§€ ì•Œì•„ì•¼ í•œë‹¤.
Action 1: Search["current US president 2024"]
Observation 1: Joe Biden is the current president.

Thought 2: Joe Bidenì˜ ìƒë…„ì›”ì¼ì„ ì°¾ì•„ì•¼ í•œë‹¤.
Action 2: Search["Joe Biden birth date"]
Observation 2: Born November 20, 1942

Thought 3: 2024 - 1942 = 82ì„¸
Action 3: Calculate[2024 - 1942]
Observation 3: 82

Answer: í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ Joe Bidenì€ 82ì„¸ì…ë‹ˆë‹¤.
```

### êµ¬í˜„

```python
from typing import List, Dict, Any
import openai

class ReActAgent:
    def __init__(self, llm, tools):
        """
        llm: Language model
        tools: Dict of available tools
        """
        self.llm = llm
        self.tools = tools
        self.max_steps = 10
    
    def run(self, question: str) -> str:
        """Run ReAct loop"""
        context = f"Question: {question}\n\n"
        
        for step in range(self.max_steps):
            # 1. Think
            prompt = self._create_prompt(context)
            response = self.llm.generate(prompt)
            
            # Parse response
            thought, action, action_input = self._parse_response(response)
            
            context += f"Thought {step+1}: {thought}\n"
            context += f"Action {step+1}: {action}[{action_input}]\n"
            
            # 2. Act
            if action == "Finish":
                return action_input
            
            if action not in self.tools:
                context += f"Observation {step+1}: Error - Unknown action\n"
                continue
            
            # 3. Observe
            observation = self.tools[action](action_input)
            context += f"Observation {step+1}: {observation}\n\n"
        
        return "Max steps reached without answer"
    
    def _create_prompt(self, context: str) -> str:
        return f"""Answer the following question using available tools.

Available tools:
- Search[query]: Search the web
- Calculate[expression]: Evaluate math expression
- Finish[answer]: Return final answer

Format:
Thought: [your reasoning]
Action: [tool name][input]

{context}"""
    
    def _parse_response(self, response: str):
        """Parse LLM response into thought, action, input"""
        lines = response.strip().split('\n')
        
        thought = ""
        action = ""
        action_input = ""
        
        for line in lines:
            if line.startswith("Thought:"):
                thought = line.split("Thought:", 1)[1].strip()
            elif line.startswith("Action:"):
                action_line = line.split("Action:", 1)[1].strip()
                # Parse "ActionName[input]"
                if '[' in action_line:
                    action = action_line.split('[')[0].strip()
                    action_input = action_line.split('[')[1].rstrip(']')
        
        return thought, action, action_input

# Tools
def search_tool(query: str) -> str:
    """Simulate web search"""
    # In practice: use Google API, Bing API, etc.
    results = {
        "current US president 2024": "Joe Biden is the president",
        "Joe Biden birth date": "November 20, 1942"
    }
    return results.get(query, "No results found")

def calculate_tool(expression: str) -> str:
    """Evaluate math expression"""
    try:
        result = eval(expression)
        return str(result)
    except:
        return "Error in calculation"

# Agent
agent = ReActAgent(
    llm=OpenAILLM(model="gpt-4"),
    tools={
        "Search": search_tool,
        "Calculate": calculate_tool
    }
)

# Run
answer = agent.run("í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ì˜ ë‚˜ì´ëŠ”?")
print(answer)
```

---

## Tool Use (Function Calling)

### OpenAI Function Calling

**LLMì—ê²Œ ë„êµ¬ ëª©ë¡ ì œê³µ:**

```python
import openai

tools = [
    {
        "type": "function",
        "function": {
            "name": "get_weather",
            "description": "Get current weather for a location",
            "parameters": {
                "type": "object",
                "properties": {
                    "location": {
                        "type": "string",
                        "description": "City name, e.g. Seoul"
                    },
                    "unit": {
                        "type": "string",
                        "enum": ["celsius", "fahrenheit"]
                    }
                },
                "required": ["location"]
            }
        }
    },
    {
        "type": "function",
        "function": {
            "name": "search_web",
            "description": "Search the web for information",
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "Search query"
                    }
                },
                "required": ["query"]
            }
        }
    }
]

# Call
response = openai.chat.completions.create(
    model="gpt-4",
    messages=[
        {"role": "user", "content": "ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜"}
    ],
    tools=tools,
    tool_choice="auto"
)

# LLMì´ ë„êµ¬ ì„ íƒ!
tool_calls = response.choices[0].message.tool_calls
if tool_calls:
    for tool_call in tool_calls:
        function_name = tool_call.function.name
        arguments = json.loads(tool_call.function.arguments)
        
        print(f"Function: {function_name}")
        print(f"Arguments: {arguments}")
        # Function: get_weather
        # Arguments: {'location': 'Seoul', 'unit': 'celsius'}
```

### Agent with Function Calling

```python
import json

class FunctionCallingAgent:
    def __init__(self, model="gpt-4"):
        self.model = model
        self.tools = self._define_tools()
        self.functions = self._define_functions()
    
    def _define_tools(self):
        """Tool definitions for OpenAI"""
        return [
            {
                "type": "function",
                "function": {
                    "name": "get_weather",
                    "description": "Get weather for a location",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "location": {"type": "string"}
                        },
                        "required": ["location"]
                    }
                }
            },
            {
                "type": "function",
                "function": {
                    "name": "calculate",
                    "description": "Evaluate math expression",
                    "parameters": {
                        "type": "object",
                        "properties": {
                            "expression": {"type": "string"}
                        },
                        "required": ["expression"]
                    }
                }
            }
        ]
    
    def _define_functions(self):
        """Actual function implementations"""
        return {
            "get_weather": self._get_weather,
            "calculate": self._calculate
        }
    
    def _get_weather(self, location: str) -> str:
        # Call weather API
        return f"{location}: 15Â°C, Sunny"
    
    def _calculate(self, expression: str) -> str:
        try:
            return str(eval(expression))
        except:
            return "Error"
    
    def run(self, user_message: str) -> str:
        """Run agent loop"""
        messages = [{"role": "user", "content": user_message}]
        
        while True:
            # LLM call
            response = openai.chat.completions.create(
                model=self.model,
                messages=messages,
                tools=self.tools,
                tool_choice="auto"
            )
            
            message = response.choices[0].message
            
            # No tool call â†’ final answer
            if not message.tool_calls:
                return message.content
            
            # Execute tools
            messages.append(message)
            
            for tool_call in message.tool_calls:
                function_name = tool_call.function.name
                arguments = json.loads(tool_call.function.arguments)
                
                # Execute
                result = self.functions[function_name](**arguments)
                
                # Add result to messages
                messages.append({
                    "role": "tool",
                    "tool_call_id": tool_call.id,
                    "name": function_name,
                    "content": result
                })

# ì‚¬ìš©
agent = FunctionCallingAgent()
answer = agent.run("ì„œìš¸ ë‚ ì”¨ê°€ ì–´ë•Œ? í™”ì”¨ë¡œ ë³€í™˜í•˜ë©´?")
print(answer)
# 1. get_weather("Seoul") â†’ "15Â°C"
# 2. calculate("15 * 9/5 + 32") â†’ "59Â°F"
# 3. "ì„œìš¸ì€ í˜„ì¬ 59Â°Fì…ë‹ˆë‹¤"
```

---

## LangChain Agent

**LangChainìœ¼ë¡œ ê°„ë‹¨íˆ:**

```python
from langchain.agents import initialize_agent, Tool
from langchain.agents import AgentType
from langchain.llms import OpenAI

# Define tools
tools = [
    Tool(
        name="Search",
        func=search_tool,
        description="Search the web for current information"
    ),
    Tool(
        name="Calculator",
        func=calculate_tool,
        description="Evaluate math expressions"
    )
]

# Initialize agent
llm = OpenAI(temperature=0)
agent = initialize_agent(
    tools,
    llm,
    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,
    verbose=True
)

# Run
result = agent.run("í˜„ì¬ ë¯¸êµ­ ëŒ€í†µë ¹ì˜ ë‚˜ì´ëŠ”?")
print(result)
```

**Output:**

```
> Entering new AgentExecutor chain...
I need to find who the current US president is and their age.
Action: Search
Action Input: "current US president 2024"
Observation: Joe Biden is the current president
Thought: Now I need to find Joe Biden's age
Action: Search
Action Input: "Joe Biden age"
Observation: Born November 20, 1942
Thought: I need to calculate the age
Action: Calculator
Action Input: 2024 - 1942
Observation: 82
Thought: I now know the final answer
Final Answer: Joe Biden is 82 years old

> Finished chain.
```

---

## Multi-step Planning

### Task Decomposition

**ë³µì¡í•œ ì‘ì—… ë¶„í•´:**

```
User: "Pythonìœ¼ë¡œ ì›¹ í¬ë¡¤ëŸ¬ ë§Œë“¤ì–´ì¤˜"

Agent:
1. ìš”êµ¬ì‚¬í•­ ë¶„ì„
   - ì–´ë–¤ ì‚¬ì´íŠ¸?
   - ì–´ë–¤ ë°ì´í„°?

2. ê³„íš ìˆ˜ë¦½
   - BeautifulSoup ì‚¬ìš©
   - requestsë¡œ HTML ê°€ì ¸ì˜¤ê¸°
   - ë°ì´í„° íŒŒì‹±
   - CSV ì €ì¥

3. êµ¬í˜„
   - ì½”ë“œ ì‘ì„±
   - í…ŒìŠ¤íŠ¸
   - ìˆ˜ì •

4. ì™„ë£Œ
   - ì½”ë“œ ì œê³µ
   - ì‚¬ìš©ë²• ì„¤ëª…
```

### Plan-and-Execute Agent

```python
class PlanAndExecuteAgent:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
    
    def run(self, task: str) -> str:
        # 1. Plan
        plan = self._create_plan(task)
        print("Plan:")
        for i, step in enumerate(plan):
            print(f"{i+1}. {step}")
        
        # 2. Execute
        results = []
        for step in plan:
            result = self._execute_step(step, results)
            results.append(result)
            print(f"âœ“ {step}: {result}")
        
        # 3. Synthesize
        return self._synthesize(task, results)
    
    def _create_plan(self, task: str) -> List[str]:
        """Create step-by-step plan"""
        prompt = f"""Break down this task into steps:
Task: {task}

Steps:"""
        
        response = self.llm.generate(prompt)
        steps = [s.strip() for s in response.split('\n') if s.strip()]
        return steps
    
    def _execute_step(self, step: str, previous_results: List[str]) -> str:
        """Execute a single step"""
        context = "\n".join([f"Step {i+1}: {r}" for i, r in enumerate(previous_results)])
        
        prompt = f"""Execute this step:
{step}

Previous results:
{context}

Use available tools if needed.
"""
        # Similar to ReAct execution
        return self._react_loop(prompt)
    
    def _synthesize(self, task: str, results: List[str]) -> str:
        """Combine results into final answer"""
        prompt = f"""Task: {task}

Results:
{chr(10).join([f'{i+1}. {r}' for i, r in enumerate(results)])}

Final answer:"""
        
        return self.llm.generate(prompt)
```

---

## Memory

**Agentê°€ ì´ì „ ëŒ€í™” ê¸°ì–µ:**

```python
class AgentWithMemory:
    def __init__(self, llm, tools):
        self.llm = llm
        self.tools = tools
        self.memory = []  # Conversation history
    
    def run(self, user_input: str) -> str:
        # Add to memory
        self.memory.append({"role": "user", "content": user_input})
        
        # Create prompt with memory
        prompt = self._create_prompt_with_memory()
        
        # ReAct loop
        response = self._react_loop(prompt)
        
        # Add to memory
        self.memory.append({"role": "assistant", "content": response})
        
        return response
    
    def _create_prompt_with_memory(self) -> str:
        context = "\n".join([
            f"{msg['role'].capitalize()}: {msg['content']}"
            for msg in self.memory
        ])
        
        return f"""Previous conversation:
{context}

Continue the conversation using available tools."""

# ëŒ€í™”
agent = AgentWithMemory(llm, tools)

agent.run("ì„œìš¸ ë‚ ì”¨ ì•Œë ¤ì¤˜")
# "ì„œìš¸ì€ 15ë„, ë§‘ìŒì…ë‹ˆë‹¤"

agent.run("ê·¸ëŸ¼ ë¶€ì‚°ì€?")
# Memory: "ì„œìš¸ ë‚ ì”¨" â†’ "ê·¸ëŸ¼ ë¶€ì‚°ì€?" = ë‚ ì”¨ ì§ˆë¬¸!
# "ë¶€ì‚°ì€ 18ë„, íë¦¼ì…ë‹ˆë‹¤"
```

---

## ì‹¤ì „ ì˜ˆì œ: ì½”ë“œ ì‹¤í–‰ Agent

```python
import subprocess

class CodeExecutionAgent:
    def __init__(self, llm):
        self.llm = llm
    
    def run(self, task: str) -> str:
        # 1. Generate code
        code = self._generate_code(task)
        print("Generated code:")
        print(code)
        
        # 2. Execute
        result = self._execute_code(code)
        print(f"Result: {result}")
        
        # 3. Fix if error
        if result.startswith("Error"):
            code = self._fix_code(code, result)
            result = self._execute_code(code)
        
        return result
    
    def _generate_code(self, task: str) -> str:
        prompt = f"""Write Python code for this task:
{task}

Code:"""
        return self.llm.generate(prompt)
    
    def _execute_code(self, code: str) -> str:
        try:
            # Save to file
            with open("temp.py", "w") as f:
                f.write(code)
            
            # Execute
            result = subprocess.run(
                ["python", "temp.py"],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                return result.stdout
            else:
                return f"Error: {result.stderr}"
        except subprocess.TimeoutExpired:
            return "Error: Timeout"
        except Exception as e:
            return f"Error: {str(e)}"
    
    def _fix_code(self, code: str, error: str) -> str:
        prompt = f"""Fix this code:

Code:
{code}

Error:
{error}

Fixed code:"""
        return self.llm.generate(prompt)

# ì‚¬ìš©
agent = CodeExecutionAgent(llm)
result = agent.run("í”¼ë³´ë‚˜ì¹˜ ìˆ˜ì—´ 10ê°œ ì¶œë ¥")
```

---

## ìš”ì•½

**AI Agent í•µì‹¬:**

1. **ReAct**: Reasoning + Acting
2. **Tool Use**: LLMì´ ë„êµ¬ ì‚¬ìš©
3. **Planning**: ë³µì¡í•œ ì‘ì—… ë¶„í•´
4. **Memory**: ëŒ€í™” ê¸°ì–µ

**êµ¬ì¡°:**

```
Observe â†’ Think â†’ Act â†’ Repeat
```

**ì‹¤ì „:**
- OpenAI Function Calling
- LangChain Agents
- Custom Agent êµ¬í˜„

**ë‹¤ìŒ ê¸€:**
- **Advanced Agents**: AutoGPT, BabyAGI
- **Multi-Agent Systems**: ì—¬ëŸ¬ Agent í˜‘ì—…
- **Agent Evaluation**: ì„±ëŠ¥ ì¸¡ì •

ê¸°ëŒ€í•´ì£¼ì„¸ìš”! ğŸš€

---

*ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ [GitHub](https://github.com/yhna941)ì—ì„œ í™˜ì˜í•©ë‹ˆë‹¤!*
