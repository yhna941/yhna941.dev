---
title: "MLOps #2: ì‹¤í—˜ ê´€ë¦¬ - MLflowì™€ Weights & Biases"
description: "ìˆ˜ë°± ë²ˆì˜ ì‹¤í—˜ì„ ì¶”ì í•˜ê³  ë¹„êµí•˜ë©° ì¬í˜„ ê°€ëŠ¥í•œ ML ì—°êµ¬ í™˜ê²½ì„ êµ¬ì¶•í•©ë‹ˆë‹¤."
pubDate: 2026-02-06
author: "Yh Na"
tags: ["mlops", "mlflow", "wandb", "experiment-tracking", "reproducibility"]
draft: false
---

# MLOps #2: ì‹¤í—˜ ê´€ë¦¬

**"ì–´ì œ í•™ìŠµí•œ ëª¨ë¸ì´ ì–´ë”” ê°”ì§€?"**

ì‹¤í—˜ ê´€ë¦¬ê°€ ì—†ì„ ë•Œ:
```
model_v1.pt
model_v2_final.pt
model_v2_final_REAL.pt
model_v3_this_time_for_sure.pt
model_best_95accuracy.pt â† ì´ê²Œ ë­ì˜€ë”ë¼?
```

ì‹¤í—˜ ê´€ë¦¬ê°€ ìˆì„ ë•Œ:
```
ì‹¤í—˜ #142:
- í•˜ì´í¼íŒŒë¼ë¯¸í„°: lr=0.001, batch=32
- ë©”íŠ¸ë¦­: acc=95.2%, loss=0.12
- ì½”ë“œ ë²„ì „: commit abc123
- ë°ì´í„°: train_v5.parquet
- ì¬í˜„ ê°€ëŠ¥! âœ…
```

---

## ì‹¤í—˜ ì¶”ì ì˜ í•„ìš”ì„±

### ë¬¸ì œ

**ì—°êµ¬ ì¤‘:**
```python
# ì‹¤í—˜ 1
model = Model(hidden_dim=128)
train(model, lr=0.001)
# accuracy: 92%

# ì‹¤í—˜ 2 (ë‹¤ìŒ ë‚ )
model = Model(hidden_dim=256)  # ë­ê°€ ë‹¬ë¼ì¡Œì§€?
train(model, lr=0.001)
# accuracy: 94%

# ì‹¤í—˜ 3 (ì¼ì£¼ì¼ í›„)
# ... ì‹¤í—˜ 1ì´ ë­ì˜€ë”ë¼? ğŸ¤”
```

**ì¶”ì í•´ì•¼ í•  ê²ƒ:**
1. **í•˜ì´í¼íŒŒë¼ë¯¸í„°**: lr, batch_size, hidden_dim, ...
2. **ë©”íŠ¸ë¦­**: accuracy, loss, F1, ...
3. **ì•„í‹°íŒ©íŠ¸**: ëª¨ë¸ íŒŒì¼, ì°¨íŠ¸, ë¡œê·¸
4. **í™˜ê²½**: Python ë²„ì „, ë¼ì´ë¸ŒëŸ¬ë¦¬, ì‹œë“œ
5. **ì½”ë“œ**: Git commit, ë³€ê²½ì‚¬í•­
6. **ë°ì´í„°**: ì–´ë–¤ ë°ì´í„°ì…‹ ì‚¬ìš©?

---

## MLflow

### ê¸°ë³¸ ì‚¬ìš©

```python
import mlflow
import mlflow.pytorch
import torch
import torch.nn as nn

# 1. ì‹¤í—˜ ì„¤ì •
mlflow.set_experiment("image_classification")

# 2. ì‹¤í—˜ ì‹œì‘
with mlflow.start_run(run_name="resnet50_baseline"):
    
    # 3. í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…
    params = {
        'model': 'resnet50',
        'learning_rate': 0.001,
        'batch_size': 32,
        'epochs': 50,
        'optimizer': 'Adam'
    }
    mlflow.log_params(params)
    
    # 4. ëª¨ë¸ í•™ìŠµ
    model = ResNet50()
    optimizer = torch.optim.Adam(model.parameters(), lr=params['learning_rate'])
    
    for epoch in range(params['epochs']):
        train_loss, train_acc = train_epoch(model, train_loader, optimizer)
        val_loss, val_acc = validate(model, val_loader)
        
        # 5. ë©”íŠ¸ë¦­ ë¡œê¹… (ê° epochë§ˆë‹¤)
        mlflow.log_metrics({
            'train_loss': train_loss,
            'train_acc': train_acc,
            'val_loss': val_loss,
            'val_acc': val_acc
        }, step=epoch)
        
        print(f"Epoch {epoch}: val_acc={val_acc:.4f}")
    
    # 6. ìµœì¢… ë©”íŠ¸ë¦­
    test_acc = evaluate(model, test_loader)
    mlflow.log_metric('test_acc', test_acc)
    
    # 7. ëª¨ë¸ ì €ì¥
    mlflow.pytorch.log_model(model, "model")
    
    # 8. ì•„í‹°íŒ©íŠ¸ (ì°¨íŠ¸, ì„¤ì • íŒŒì¼ ë“±)
    plot_confusion_matrix(model, test_loader, save_path='confusion_matrix.png')
    mlflow.log_artifact('confusion_matrix.png')
    
    # 9. íƒœê·¸
    mlflow.set_tags({
        'team': 'research',
        'project': 'image-classification',
        'model_architecture': 'resnet50'
    })
```

### MLflow UI

```bash
# MLflow ì„œë²„ ì‹¤í–‰
mlflow ui --backend-store-uri sqlite:///mlflow.db --port 5000

# ë¸Œë¼ìš°ì €ì—ì„œ: http://localhost:5000
```

**UI ê¸°ëŠ¥:**
- ëª¨ë“  ì‹¤í—˜ ë¹„êµ
- ë©”íŠ¸ë¦­ ì°¨íŠ¸ ì‹œê°í™”
- í•˜ì´í¼íŒŒë¼ë¯¸í„° í•„í„°ë§
- ëª¨ë¸ ë‹¤ìš´ë¡œë“œ

---

## MLflow ê³ ê¸‰ ê¸°ëŠ¥

### 1. Nested Runs (ê³„ì¸µì  ì‹¤í—˜)

```python
# ë¶€ëª¨ ì‹¤í—˜: í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰
with mlflow.start_run(run_name="hyperparameter_search") as parent_run:
    
    for lr in [0.001, 0.01, 0.1]:
        for batch_size in [16, 32, 64]:
            # ìì‹ ì‹¤í—˜
            with mlflow.start_run(
                run_name=f"lr_{lr}_batch_{batch_size}",
                nested=True
            ):
                mlflow.log_params({
                    'learning_rate': lr,
                    'batch_size': batch_size
                })
                
                model = train_model(lr, batch_size)
                acc = evaluate(model)
                
                mlflow.log_metric('accuracy', acc)
    
    # ë¶€ëª¨ ì‹¤í—˜ì— ìµœê³  ì„±ëŠ¥ ê¸°ë¡
    best_acc = max(all_accuracies)
    mlflow.log_metric('best_accuracy', best_acc)
```

### 2. Autologging (ìë™ ë¡œê¹…)

```python
import mlflow.pytorch

# PyTorch autologging í™œì„±í™”
mlflow.pytorch.autolog(
    log_every_n_epoch=1,
    log_models=True,
    disable=False,
    exclusive=False,
    disable_for_unsupported_versions=False,
    silent=False
)

# ì´ì œ ìë™ìœ¼ë¡œ ë¡œê¹…ë¨!
with mlflow.start_run():
    model = YourModel()
    train(model)  # ë©”íŠ¸ë¦­, íŒŒë¼ë¯¸í„°, ëª¨ë¸ ìë™ ì €ì¥
```

**ì§€ì› í”„ë ˆì„ì›Œí¬:**
- PyTorch, TensorFlow, Keras
- XGBoost, LightGBM, Scikit-learn
- Spark MLlib, Fastai

### 3. Model Registry (í”„ë¡œë•ì…˜ ê´€ë¦¬)

```python
from mlflow.tracking import MlflowClient

client = MlflowClient()

# 1. ëª¨ë¸ ë“±ë¡
run_id = "abc123"
model_uri = f"runs:/{run_id}/model"

model_details = mlflow.register_model(
    model_uri,
    "ImageClassifier"
)

# 2. ëª¨ë¸ ë²„ì „ ì •ë³´
print(f"Name: {model_details.name}")
print(f"Version: {model_details.version}")

# 3. Stage ê´€ë¦¬
client.transition_model_version_stage(
    name="ImageClassifier",
    version=5,
    stage="Staging"  # None, Staging, Production, Archived
)

# 4. ëª¨ë¸ ì„¤ëª… ì¶”ê°€
client.update_model_version(
    name="ImageClassifier",
    version=5,
    description="ResNet50 trained on ImageNet, 95% accuracy"
)

# 5. Production ëª¨ë¸ ë¡œë“œ
model = mlflow.pyfunc.load_model("models:/ImageClassifier/Production")
predictions = model.predict(test_data)

# 6. ëª¨ë¸ ë¹„êµ
def compare_model_versions(model_name, versions):
    comparison = []
    
    for version in versions:
        mv = client.get_model_version(model_name, version)
        run = client.get_run(mv.run_id)
        
        comparison.append({
            'version': version,
            'stage': mv.current_stage,
            'accuracy': run.data.metrics.get('test_acc'),
            'created': mv.creation_timestamp
        })
    
    return pd.DataFrame(comparison)

df = compare_model_versions("ImageClassifier", [3, 4, 5])
print(df)
```

---

## Weights & Biases (W&B)

### ê¸°ë³¸ ì‚¬ìš©

```python
import wandb

# 1. ì´ˆê¸°í™”
wandb.init(
    project="image-classification",
    name="resnet50-experiment",
    config={
        'learning_rate': 0.001,
        'batch_size': 32,
        'epochs': 50,
        'model': 'resnet50'
    }
)

# 2. í•™ìŠµ ë£¨í”„
for epoch in range(wandb.config.epochs):
    train_loss = train_epoch(model, train_loader)
    val_loss = validate(model, val_loader)
    
    # 3. ë©”íŠ¸ë¦­ ë¡œê¹…
    wandb.log({
        'epoch': epoch,
        'train_loss': train_loss,
        'val_loss': val_loss,
        'learning_rate': optimizer.param_groups[0]['lr']
    })

# 4. ì™„ë£Œ
wandb.finish()
```

### W&B ê³ ê¸‰ ê¸°ëŠ¥

#### 1. ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ë¡œê¹…

```python
import wandb
import matplotlib.pyplot as plt

# ì´ë¯¸ì§€ ë¡œê¹…
images = []
for img, pred, label in zip(sample_images, predictions, labels):
    images.append(wandb.Image(
        img,
        caption=f"Pred: {pred}, Label: {label}"
    ))

wandb.log({"predictions": images})

# Matplotlib ì°¨íŠ¸
fig, ax = plt.subplots()
ax.plot(train_losses)
ax.set_title("Training Loss")

wandb.log({"loss_curve": wandb.Image(fig)})
plt.close(fig)

# Confusion Matrix
wandb.log({
    "confusion_matrix": wandb.plot.confusion_matrix(
        probs=None,
        y_true=all_labels,
        preds=all_preds,
        class_names=class_names
    )
})
```

#### 2. í•˜ì´í¼íŒŒë¼ë¯¸í„° Sweep (ìë™ íŠœë‹)

```python
# sweep ì„¤ì •
sweep_config = {
    'method': 'bayes',  # grid, random, bayes
    'metric': {
        'name': 'val_accuracy',
        'goal': 'maximize'
    },
    'parameters': {
        'learning_rate': {
            'distribution': 'log_uniform_values',
            'min': 1e-5,
            'max': 1e-1
        },
        'batch_size': {
            'values': [16, 32, 64, 128]
        },
        'dropout': {
            'distribution': 'uniform',
            'min': 0.1,
            'max': 0.5
        },
        'optimizer': {
            'values': ['adam', 'sgd', 'rmsprop']
        }
    }
}

# Sweep ì´ˆê¸°í™”
sweep_id = wandb.sweep(sweep_config, project="image-classification")

# í•™ìŠµ í•¨ìˆ˜
def train():
    wandb.init()
    
    # wandb.configì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê°€ì ¸ì˜¤ê¸°
    config = wandb.config
    
    model = create_model(
        dropout=config.dropout,
        optimizer=config.optimizer
    )
    
    for epoch in range(50):
        train_loss = train_epoch(
            model,
            train_loader,
            lr=config.learning_rate,
            batch_size=config.batch_size
        )
        val_acc = validate(model, val_loader)
        
        wandb.log({
            'train_loss': train_loss,
            'val_accuracy': val_acc
        })

# Sweep ì‹¤í–‰ (10íšŒ ì‹œë„)
wandb.agent(sweep_id, train, count=10)
```

#### 3. Artifacts (ë°ì´í„°/ëª¨ë¸ ë²„ì €ë‹)

```python
import wandb

run = wandb.init(project="my-project")

# ë°ì´í„°ì…‹ ì €ì¥
artifact = wandb.Artifact('training-data', type='dataset')
artifact.add_file('train.csv')
artifact.add_file('val.csv')
run.log_artifact(artifact)

# ëª¨ë¸ ì €ì¥
model_artifact = wandb.Artifact('resnet50', type='model')
model_artifact.add_file('model.pt')
run.log_artifact(model_artifact)

# ì‚¬ìš© (ë‹¤ë¥¸ ì‹¤í—˜ì—ì„œ)
run = wandb.init(project="my-project")

# ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ
artifact = run.use_artifact('training-data:latest')
artifact_dir = artifact.download()

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
model_artifact = run.use_artifact('resnet50:v3')
model_path = model_artifact.download()
model = torch.load(f"{model_path}/model.pt")
```

#### 4. Reports (ì‹¤í—˜ ê³µìœ )

```python
# W&B UIì—ì„œ ë¦¬í¬íŠ¸ ìƒì„± í›„...

# APIë¡œ ë¦¬í¬íŠ¸ ìƒì„±
import wandb

api = wandb.Api()

# ì‹¤í—˜ ê°€ì ¸ì˜¤ê¸°
runs = api.runs("my-project")

# ë¹„êµ í…Œì´ë¸”
comparison = []
for run in runs:
    comparison.append({
        'name': run.name,
        'accuracy': run.summary.get('val_accuracy'),
        'loss': run.summary.get('val_loss'),
        'config': run.config
    })

df = pd.DataFrame(comparison)
print(df.sort_values('accuracy', ascending=False))
```

---

## MLflow vs W&B

### ë¹„êµ

| Feature | MLflow | W&B |
|---------|--------|-----|
| **ë¹„ìš©** | ë¬´ë£Œ (self-hosted) | Free tier + ìœ ë£Œ |
| **UI** | ê¸°ë³¸ì  | ê°•ë ¥, ì¸í„°ë™í‹°ë¸Œ |
| **ì„¤ì¹˜** | ì‰¬ì›€ | ë” ì‰¬ì›€ |
| **ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬** | âœ… ê°•ë ¥ | âœ… Artifacts |
| **í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹** | âŒ | âœ… Sweep |
| **ì‹¤ì‹œê°„ ì‹œê°í™”** | ì œí•œì  | âœ… ê°•ë ¥ |
| **í˜‘ì—…** | ì œí•œì  | âœ… ê°•ë ¥ |
| **ìì²´ í˜¸ìŠ¤íŒ…** | âœ… | âœ… (Enterprise) |

### í•¨ê»˜ ì‚¬ìš©í•˜ê¸°

```python
import mlflow
import wandb

# ë‘˜ ë‹¤ ì‚¬ìš©!
wandb.init(project="my-project", sync_tensorboard=True)
mlflow.set_experiment("my-experiment")

with mlflow.start_run():
    for epoch in range(50):
        loss = train_epoch()
        acc = validate()
        
        # MLflow
        mlflow.log_metrics({
            'loss': loss,
            'accuracy': acc
        }, step=epoch)
        
        # W&B
        wandb.log({
            'loss': loss,
            'accuracy': acc
        })
    
    # MLflowì— ëª¨ë¸ ì €ì¥
    mlflow.pytorch.log_model(model, "model")
    
    # W&Bì—ë„ ì €ì¥
    artifact = wandb.Artifact('model', type='model')
    artifact.add_file('model.pt')
    wandb.log_artifact(artifact)

wandb.finish()
```

---

## ì¬í˜„ ê°€ëŠ¥ì„± (Reproducibility)

### 1. í™˜ê²½ ì¶”ì 

```python
import mlflow
import torch
import random
import numpy as np

def set_seed(seed):
    """ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •"""
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

with mlflow.start_run():
    seed = 42
    set_seed(seed)
    
    # í™˜ê²½ ì •ë³´ ë¡œê¹…
    mlflow.log_params({
        'seed': seed,
        'python_version': sys.version,
        'torch_version': torch.__version__,
        'cuda_version': torch.version.cuda,
        'gpu_name': torch.cuda.get_device_name(0)
    })
    
    # Git ì •ë³´
    import subprocess
    commit = subprocess.check_output(['git', 'rev-parse', 'HEAD']).decode().strip()
    mlflow.log_param('git_commit', commit)
    
    # ì½”ë“œ ì €ì¥
    mlflow.log_artifact('train.py')
    mlflow.log_artifact('model.py')
```

### 2. Dockerë¡œ í™˜ê²½ ìº¡ìŠí™”

```dockerfile
# Dockerfile
FROM pytorch/pytorch:2.0.0-cuda11.7-cudnn8-runtime

WORKDIR /app

# ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install -r requirements.txt

# ì½”ë“œ ë³µì‚¬
COPY . .

# MLflow í™˜ê²½ë³€ìˆ˜
ENV MLFLOW_TRACKING_URI=http://mlflow-server:5000

# í•™ìŠµ ì‹¤í–‰
CMD ["python", "train.py"]
```

```yaml
# docker-compose.yml
version: '3.8'

services:
  mlflow:
    image: mlflow-server
    ports:
      - "5000:5000"
    volumes:
      - ./mlruns:/mlflow/mlruns
    command: mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow.db
  
  training:
    build: .
    depends_on:
      - mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./data:/app/data
      - ./models:/app/models
```

---

## ì‹¤ì „ ì›Œí¬í”Œë¡œìš°

### ì—°êµ¬ íŒ€ ì›Œí¬í”Œë¡œìš°

```python
class ExperimentManager:
    """ì‹¤í—˜ ê´€ë¦¬ í—¬í¼"""
    
    def __init__(self, project_name, experiment_name):
        self.project = project_name
        self.experiment = experiment_name
        
        # W&B ì´ˆê¸°í™”
        wandb.init(project=project_name)
        
        # MLflow ì´ˆê¸°í™”
        mlflow.set_experiment(experiment_name)
    
    def start_run(self, run_name, config):
        """ì‹¤í—˜ ì‹œì‘"""
        # W&B run
        wandb.run.name = run_name
        wandb.config.update(config)
        
        # MLflow run
        self.mlflow_run = mlflow.start_run(run_name=run_name)
        mlflow.log_params(config)
        
        return self
    
    def log_metrics(self, metrics, step=None):
        """ë©”íŠ¸ë¦­ ë¡œê¹…"""
        wandb.log(metrics, step=step)
        mlflow.log_metrics(metrics, step=step)
    
    def log_model(self, model, name):
        """ëª¨ë¸ ì €ì¥"""
        # W&B
        artifact = wandb.Artifact(name, type='model')
        torch.save(model.state_dict(), f'{name}.pt')
        artifact.add_file(f'{name}.pt')
        wandb.log_artifact(artifact)
        
        # MLflow
        mlflow.pytorch.log_model(model, name)
    
    def finish(self):
        """ì‹¤í—˜ ì¢…ë£Œ"""
        wandb.finish()
        mlflow.end_run()

# ì‚¬ìš©
manager = ExperimentManager("image-classification", "resnet-experiments")

config = {
    'learning_rate': 0.001,
    'batch_size': 32,
    'epochs': 50
}

manager.start_run("baseline", config)

for epoch in range(config['epochs']):
    loss = train_epoch()
    acc = validate()
    
    manager.log_metrics({
        'loss': loss,
        'accuracy': acc
    }, step=epoch)

manager.log_model(model, "resnet50")
manager.finish()
```

---

## ìš”ì•½

**ì‹¤í—˜ ê´€ë¦¬ í•µì‹¬:**

1. **ì¶”ì **: í•˜ì´í¼íŒŒë¼ë¯¸í„°, ë©”íŠ¸ë¦­, ì½”ë“œ, í™˜ê²½
2. **ë¹„êµ**: ì‹¤í—˜ ê°„ ì„±ëŠ¥ ë¹„êµ
3. **ì¬í˜„**: ê°™ì€ ê²°ê³¼ ë‹¤ì‹œ ë§Œë“¤ê¸°
4. **ê³µìœ **: íŒ€ê³¼ ê²°ê³¼ ê³µìœ 

**MLflow:**
- Self-hosted
- ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê°•ë ¥
- Production ê´€ë¦¬

**W&B:**
- SaaS (ì‰¬ìš´ ì‹œì‘)
- í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- í˜‘ì—… ê¸°ëŠ¥ ê°•ë ¥

**Best Practices:**
- ëª¨ë“  ì‹¤í—˜ ì¶”ì 
- ì‹œë“œ ê³ ì •
- Git commit ê¸°ë¡
- í™˜ê²½ ì •ë³´ ì €ì¥

**ë‹¤ìŒ ê¸€:**
- **MLOps #3**: ëª¨ë‹ˆí„°ë§ & A/B í…ŒìŠ¤íŒ…
- **Serving #1**: ì¶”ë¡  ì„œë²„ ìµœì í™”
- **Serving #2**: ë°°ì¹˜ vs ìŠ¤íŠ¸ë¦¬ë°

ê¸°ëŒ€í•´ì£¼ì„¸ìš”! ğŸš€

---

*ì§ˆë¬¸ì´ë‚˜ í”¼ë“œë°±ì€ [GitHub](https://github.com/yhna941)ì—ì„œ í™˜ì˜í•©ë‹ˆë‹¤!*
